{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Objective\n",
    "In this exercise, your goal is to correctly identify digits from a dataset of handwritten images.\n",
    "\n",
    "The dataset contains gray-scale images of hand-drawn digits, from zero through nine. It contains 42,000 images.\n",
    "Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "The data set, has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "You are expected to:\n",
    "- Experiment with different models and settings and decide on the best model for this dataset\n",
    "- Write a brief report (2-4 pages maximum) describing the choices you made and the evaluation you performed"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Utilities\n",
    "import os \n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_digits     = pd.read_csv('digit_recognizer_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_digit():\n",
    "    fig, axs = plt.subplots(2,5,sharex='col', sharey='row',\n",
    "                        gridspec_kw={'hspace': 0, 'wspace': 0},figsize=(19,8))\n",
    "    fig.suptitle('MNIST sample digits')\n",
    "    for i in range(0,10):\n",
    "        digit = all_digits.loc[all_digits['label'] == i]\n",
    "        digit = digit.iloc[random.randint(0, len(digit.index))][1:]\n",
    "        digit = np.array(digit, dtype='float')\n",
    "        pixels = digit.reshape((28, 28))\n",
    "        axs[int(i/5), i % 5].imshow(pixels, cmap='gray')\n",
    "\n",
    "\n",
    "print_digit()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = all_digits.columns[1:]\n",
    "X = all_digits[features]\n",
    "y = all_digits['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255.,y,test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models Declaration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list, with one item per algorithm. Each item has a name, and a classifier object.\n",
    "models = []\n",
    "models.append(('XGB',  XGBClassifier()))\n",
    "models.append(('LR' ,  LogisticRegression()))\n",
    "models.append(('LDA',  LinearDiscriminantAnalysis()))\n",
    "models.append(('kNN',  KNeighborsClassifier()))\n",
    "models.append(('DT' ,  DecisionTreeClassifier()))\n",
    "models.append(('MLP',  MLPClassifier()))\n",
    "models.append(('RF' ,  RandomForestClassifier()))\n",
    "models.append(('SVM',  SVC()))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Models Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names   = []\n",
    "for name, model in models:\n",
    "  cv_results = cross_val_score(model, X_train, y_train, scoring='accuracy', n_jobs= -1, verbose=2)\n",
    "  results.append(cv_results)\n",
    "  names.append(name)\n",
    "  print(\"%03s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(results)\n",
    "plt.xticks(list(range(1,len(names)+1)), names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HyperParameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth      = [5   , 6   , 7   ]\n",
    "subsample      = [0.7 , 0.8 , 0.9 ]\n",
    "reg_alpha      = [0   , 0.1 , 0.2 ]\n",
    "reg_lamda      = [1   , 1.1 , 1.2 ]\n",
    "min_split_loss = [0   , 5   , 10  ]\n",
    "\n",
    "iterables = [ max_depth, subsample, reg_alpha, reg_lamda, learning_rate, min_split_loss ]\n",
    "\n",
    "combinations = []\n",
    "for t in itertools.product(*iterables):\n",
    "    combinations.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_accuracy = []\n",
    "eval_set = [(X_train,y_train), (X_test, y_test)]\n",
    "for params in combinations:\n",
    "    model = XGBClassifier(n_estimators=5,n_jobs=-1,verbose=0,max_depth=params[0],subsample=params[1],\n",
    "                                reg_alpha=params[2],reg_lambda=params[3],min_split_loss=params[4])\n",
    "    model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=[\"merror\"], eval_set=eval_set)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    params_accuracy.append(accuracy)\n",
    "\n",
    "best_params = combinations[np.argmax(params_accuracy)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = xgb.XGBClassifier(n_estimators=500,n_jobs=-1,max_depth=7,subsample=0.9)\n",
    "eval_set = [(X_train,y_train), (X_test, y_test)]\n",
    "model.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=[\"merror\"], eval_set=eval_set)\n",
    "y_pred = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# retrieve performance metrics\n",
    "results = model.evals_result()\n",
    "epochs = len(results['validation_0']['merror'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "# plot Accuracy\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['merror'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['merror'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('merror')\n",
    "plt.title('XGBoost merror')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}